---
title: "cleanDataPrep"
author: "Camille & Maja"
date: "2025-09-02"
output: html_document
---

```{r clean final dataset- newest dataset}

library(tidyverse)

data3 <- read.csv('data/mergedMonitors_v6.csv', sep = ',', allowEscapes = T) # replace with provided sample dataset e.g., sampleAQM.csv

data3$type <- ifelse(!data3$isMonitor, "Sensor", "Reference Grade")

data3$type <- ifelse(data3$isEmbassy, "Embassy", data3$type)

data3 <- subset(data3, database %in% c("WAQI", "PurpleAir", "OpenAQ"))

data3 <- subset(data3, firstUpdated < ymd_hms("2024-05-01T00:00:00+00:00") | database == "WAQI")

# Calculate the difference in days
data3$diffDays <- as.numeric(difftime(data3$lastUpdated, data3$firstUpdated, units = "days"))

# Remove potential low quality points
data3Sub <- subset(data3, (diffDays > 30 | firstUpdated > ymd_hms("2024-02-01T00:00:00+00:00")) | database == "WAQI")

write.csv(x=data3Sub, file="outputData/mergedMonitors2_final.csv", row.names = F)

```

```{r setup, include=FALSE}

library(tidyverse)
library(sf)
library(vdemdata)
library(countrycode)
library(terra)

# functions are useful for chunks 2 and 3
sf_to_dfPoints <- function(sf){
  df_main <- sf %>%
    st_as_sf() %>%
    mutate(longitude = st_coordinates(.)[,1],
           latitude = st_coordinates(.)[,2]) %>%
    st_set_geometry(NULL) %>%
    as.data.frame()
  
  return(df_main)
}

sf_to_dfPoly <- function(sf){
  df_main <- sf %>%
    st_as_sf() %>%
    st_set_geometry(NULL) %>%
    as.data.frame()
  
  return(df_main)
}

```


```{r spatial join SHP UC - monitor big database}
"%ni%" = Negate("%in%")

data3 <- read.csv('outputData/mergedMonitors2_final.csv', sep = ',', allowEscapes = T)

# colors <- c("#91C17F", "#D0B077", "#FFCF00", "#4DC6B9", "#E5E4E2", "#FFA5FF", "#00FFE5", "#EC9FAE", "#D6A2E0", "#88B9E5")

# Calculate the difference in days
data3$diffDays <- as.numeric(difftime(data3$lastUpdated, data3$firstUpdated, units = "days"))

data3Sub <- subset(data3, (diffDays > 30 | firstUpdated > ymd_hms("2024-02-01T00:00:00+00:00")) | database == "WAQI")

UCs <- st_read("data/UC_fixed_geom.gpkg")

data3Sub <- subset(data3Sub, !is.na(longitude))
data3Sub_sf <- st_as_sf(data3Sub, coords = c("longitude", "latitude"), crs = 4326)

# Define the function
countPointsInUCs <- function(points_sf, UCs, condition = "TRUE") {
  # Filter data based on the condition
  # The condition is parsed from a string to an expression
  filtered_points <- points_sf %>%
    filter(eval(parse(text = condition)))
  
  # Perform spatial join with filtered points
  points_within_fuas <- st_join(filtered_points, UCs, join = st_within) %>%
    group_by(ID_HDC_G0) %>%
    summarise(numberMonitors = n(), .groups = 'drop')
  
  # Convert to a regular dataframe if needed
  points_within_fuas_df <- sf_to_dfPoly(points_within_fuas)
  
  # Ensure all UCs are included, even those without points
  nbMonitorUC <- UCs %>%
    dplyr::select(ID_HDC_G0) %>%
    left_join(points_within_fuas_df, by = "ID_HDC_G0") %>%
    mutate(numberMonitors = replace_na(numberMonitors, 0))
  
  nbMonitorUC <- sf_to_dfPoly(nbMonitorUC)

  # Return the result
  return(nbMonitorUC)
}

result_ref <- countPointsInUCs(data3Sub_sf, UCs, condition = "type == 'Reference Grade'") %>% 
  rename(numberRefMonitors = numberMonitors)

result_sens <- countPointsInUCs(data3Sub_sf, UCs, condition = "type == 'Sensor'") %>% 
  rename(numberSensMonitors = numberMonitors)

result_USEmbassy <- countPointsInUCs(data3Sub_sf, UCs, condition = "type == 'Embassy'") %>% 
  rename(numberUSEmbassyMonitors = numberMonitors)

result_OpenAQ <- countPointsInUCs(data3Sub_sf, UCs, condition = "database == 'OpenAQ'") %>% 
  rename(numberOpenAQMonitors = numberMonitors)

result_WAQI <- countPointsInUCs(data3Sub_sf, UCs, condition = "database == 'WAQI'") %>% 
  rename(numberWAQIMonitors = numberMonitors)

result_PurpleAir <- countPointsInUCs(data3Sub_sf, UCs, condition = "database == 'PurpleAir'") %>% 
  rename(numberPurpleAirMonitors = numberMonitors)

# To count all points, you can omit the condition or set it to TRUE
result_all <- countPointsInUCs(data3Sub_sf, UCs)

UCs_r <- merge(UCs, result_all, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_ref, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_sens, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_USEmbassy, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_OpenAQ, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_WAQI, by = "ID_HDC_G0", all.x=T)
UCs_r <- merge(UCs_r, result_PurpleAir, by = "ID_HDC_G0", all.x=T)

UCs_nsf <- sf_to_dfPoly(UCs_r)

write.csv(x=UCs_nsf, file="outputData/UC_nsf_monitorsOpenAQWAQI.csv", row.names = F)

```

```{r country csv level data}

UCs_nsf <- read.csv("outputData/UC_nsf_monitorsOpenAQWAQI.csv", sep=",", header=T) # if need to load

## We merge different datasets to the UCs for analysis

# first OECD Y/N
oecd <- read.csv("data/oecd.csv", sep=",", header=T)
oecd$oecd <- ifelse(oecd$Accession < 2020, "OECD", "nonOECD")

oecd <- oecd %>% dplyr::select(Code, oecd) 

UCs_nsf <- merge(UCs_nsf, oecd, by.x = "CTR_MN_ISO", by.y = "Code", all.x = T, all.y = F)

# testing to see if data makes sense
test <- UCs_nsf %>% group_by(oecd) %>% 
  count(CTR_MN_NM) %>%
  ungroup()

UCs_nsf$oecd <- ifelse(is.na(UCs_nsf$oecd), "nonOECD", UCs_nsf$oecd)

# second V-dem

vdem_data <- vdem

summary_vdem <- vdem_data %>%
  filter(year >= 2000, year <= 2015) %>%  # Filter for years 2000 to 2015
  group_by(country_text_id) %>% 
  summarise(mean_edi = mean(v2x_polyarchy, na.rm = TRUE),
            mean_ldi = mean(v2x_libdem, na.rm = TRUE))

UCs_nsf <- merge(UCs_nsf, summary_vdem, by.x = "CTR_MN_ISO", by.y = "country_text_id", all.x = T, all.y = F)

UCs_nsf$vdem_bin <- as.factor(ifelse(UCs_nsf$mean_edi > 0.5, "democracy", "non-democracy"))
UCs_nsf$vdemLib_bin <- as.factor(ifelse(UCs_nsf$mean_ldi > 0.5, "democracy", "non-democracy"))

# testing to see if data makes sense
test <- UCs_nsf %>% group_by(vdem_bin) %>% 
  count(CTR_MN_NM) %>%
  ungroup()

# third war

ucdp <- read.csv("data/UcdpPrioConflict_v23_1.csv")

ucdp_sep <- separate_rows(ucdp, location, sep = ",\\s*") #! Here this is a methodological question (do we split columns that have 2 or more countries as location?) -> here we do

# Function to summarize data
summarize_conflicts <- function(data, start_year, end_year, onset_name, last_year_name, intensity_name) {
  data %>%
    filter(year >= start_year & year <= end_year) %>%
    group_by(country = location) %>%
    summarize(
      !!last_year_name := max(year),
      !!intensity_name := max(cumulative_intensity),
      !!onset_name := 1,
      .groups = 'drop'
    )
}

# Summarize for 2000-2022
dt_ucdp_2022 <- summarize_conflicts(ucdp_sep, 2000, 2022, "conflict_onset_2022", "last_conflict_year_22", "conflict_cumulative_intensity_22")

dt_ucdp_2022$country <- ifelse(dt_ucdp_2022$country == "Yemen (North Yemen)", "Yemen", dt_ucdp_2022$country)

dt_ucdp_2022$ISO <- countrycode(
sourcevar = dt_ucdp_2022$country,
origin = 'country.name',
destination = "iso3c"
)

dt_ucdp_2022 <- dt_ucdp_2022 %>% dplyr::select(ISO, conflict_cumulative_intensity_22)

UCs_nsf <- merge(UCs_nsf, dt_ucdp_2022, by.x = "CTR_MN_ISO", by.y = "ISO", all.x = T, all.y = F)

UCs_nsf$conflict_cumulative_intensity_22 <- ifelse(UCs_nsf$conflict_cumulative_intensity_22 == 1, "war", "nowar")
UCs_nsf$conflict_cumulative_intensity_22 <- ifelse(is.na(UCs_nsf$conflict_cumulative_intensity_22), "nowar", UCs_nsf$conflict_cumulative_intensity_22)

# testing to see if data makes sense
test <- UCs_nsf %>% group_by(conflict_cumulative_intensity_22) %>% 
  count(CTR_MN_NM) %>%
  ungroup()

# fourth corruption

CPI <- read.csv("data/CPI2022_GlobalResultsTrends.csv", sep = ";")

CPI <- CPI %>%
  mutate(across(starts_with("CPIscore"), as.numeric))

CPI <- CPI %>% 
  rowwise() %>%
  mutate(CPI_2012_2022 = mean(c_across(matches("CPIscore20(1[2-9]|20|21|22)")), na.rm = TRUE)) %>%
  ungroup() %>% dplyr::select(ISO3, CPI_2012_2022)

UCs_nsf <- merge(UCs_nsf, CPI, by.x = "CTR_MN_ISO", by.y = "ISO3", all.x = T, all.y = F)

UCs_nsf$CPI_2012_2022 <- (100 - UCs_nsf$CPI_2012_2022) # Reversing scale so that high is more corrupted

# fifth capital, from the UC dataset
UCs_nsf$capital <- ifelse(UCs_nsf$TT2CC == 0, 1, 0)

# identifying UCs that have NA as capital -> visual inspection is ok to say they are not capitals
test <- subset(UCs_nsf, is.na(capital) & !is.na(mean_edi))

UCs_nsf$capital[which((is.na(UCs_nsf$capital) & !is.na(UCs_nsf$mean_edi)))] <- 0

write.csv(x=UCs_nsf, file="outputData/UC_nsf_merged_monitorsOpenAQWAQI.csv", row.names = F)

```

```{r merge UC and new GDP and Pollution data}

pollutionDataVanD <- terra::rast("dataRaster/vanD20002016.tif")
UCs <- st_read("data/UC_fixed_geom.gpkg")
UCsterra <- terra::vect(UCs)

valuesAtUCs <- terra::extract(pollutionDataVanD, UCsterra, fun=mean, weights = T, ID = F, na.rm=TRUE)
valuesAtUCs <- valuesAtUCs %>% rename(pm25VanD20002016 = GWRPM25)

newUCs <- cbind(UCsterra, valuesAtUCs)

noSVUC <- as.data.frame(newUCs) %>% select(ID_HDC_G0, pm25VanD20002016)

write.csv(x=noSVUC, file="outputData/UC_nsf_monitors_mergedGrid.csv", row.names = F)

```

